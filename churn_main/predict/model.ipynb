{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d02530",
   "metadata": {},
   "source": [
    "### Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b9e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages / libraries\n",
    "import os #provides functions for interacting with the operating system\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, k_means\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1209425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767851d2",
   "metadata": {},
   "source": [
    "###  Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e872d532",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10127, 23)\n"
     ]
    }
   ],
   "source": [
    "# Loading the data data\n",
    "raw_data = pd.read_csv(r\"C:\\Users\\user\\Desktop\\AI projects\\Churn-prediction\\BankChurners.csv\")\n",
    "\n",
    "# print the shape\n",
    "print(raw_data.shape)\n",
    "# drop unused columns\n",
    "raw_data = raw_data.drop(['CLIENTNUM', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c579e2",
   "metadata": {},
   "source": [
    "### Feature selecting\n",
    "In this model - Kmeans -  I will seslect just three features from the numerical ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a42d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing numerical\n",
    "numerical = raw_data.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a72c5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = numerical.drop(['Customer_Age', 'Dependent_count','Months_on_book', 'Total_Relationship_Count',\n",
    "       'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit','Total_Revolving_Bal','Total_Amt_Chng_Q4_Q1','Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1' ], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3739c46",
   "metadata": {},
   "source": [
    "### K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d6580a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "new_data = scaler.fit_transform(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36235f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the data set for X_train\n",
    "X_train = new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bbe7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running K means with multible Ks, good model is one with low inertia AND a low number of clusters (K)\n",
    "\n",
    "no_of_clusters = range(2,10) #[2,3,4,5,6,7,8,9]\n",
    "inertia = []  # measuring the distance between each data point and its centroid \n",
    "\n",
    "\n",
    "for f in no_of_clusters:\n",
    "    kmeans = KMeans(n_clusters=f, random_state=2)\n",
    "    kmeans = kmeans.fit(X_train)\n",
    "    u = kmeans.inertia_\n",
    "    inertia.append(u)\n",
    "    print(\"The innertia for :\", f, \"Clusters is:\", u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e155d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the plot for Intertia - elbow method\n",
    "fig, (ax1) = plt.subplots(1, figsize=(10,6))\n",
    "xx = np.arange(len(no_of_clusters))\n",
    "ax1.plot(xx, inertia)\n",
    "ax1.set_xticks(xx)\n",
    "ax1.set_xticklabels(no_of_clusters, rotation='vertical')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia Score')\n",
    "plt.title(\"Inertia Plot per k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "262b063d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster 0</th>\n",
       "      <th>Cluster 1</th>\n",
       "      <th>Cluster 2</th>\n",
       "      <th>Cluster 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4673</td>\n",
       "      <td>792</td>\n",
       "      <td>3318</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster 0  Cluster 1  Cluster 2  Cluster 3\n",
       "0       4673        792       3318       1344"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# Instantiate the KMeans models\n",
    "#\n",
    "km = KMeans(n_clusters=4, random_state=42)\n",
    "#\n",
    "# Fit the KMeans model\n",
    "#\n",
    "predictions = km.fit_predict(X_train)\n",
    "\n",
    "# calculating the Counts of the cluster\n",
    "unique, counts = np.unique(predictions, return_counts=True)\n",
    "counts = counts.reshape(1,4)\n",
    "\n",
    "# Creating a dataframe\n",
    "countscldf = pd.DataFrame(counts, columns = [\"Cluster 0\",\"Cluster 1\",\"Cluster 2\", \"Cluster 3\"])\n",
    "\n",
    "# display\n",
    "countscldf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb458804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouetter Score: 0.482\n"
     ]
    }
   ],
   "source": [
    "# Calculate Silhoutte Score\n",
    "from sklearn import metrics\n",
    "\n",
    "score = metrics.silhouette_score(X_train, km.labels_, metric='euclidean')\n",
    "#\n",
    "# Print the score\n",
    "#\n",
    "print('Silhouetter Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d874961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Running PCA to Visualize the data\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Trying with Dimentionality reduction and then Kmeans\n",
    "X = X_train\n",
    "y_num = predictions\n",
    "\n",
    "n_components = X.shape[1]\n",
    "\n",
    "# Running PCA with all components\n",
    "pca = PCA(n_components=n_components, random_state = 420)\n",
    "X_r = pca.fit(X).transform(X)\n",
    "\n",
    "\n",
    "# Calculating the 95% Variance\n",
    "total_variance = sum(pca.explained_variance_)\n",
    "print(\"Total Variance in our dataset is: \", total_variance)\n",
    "var_95 = total_variance * 0.95\n",
    "print(\"The 95% variance we want to have is: \", var_95)\n",
    "print(\"\")\n",
    "\n",
    "# Creating a df with the components and explained variance\n",
    "a = zip(range(0,n_components), pca.explained_variance_)\n",
    "a = pd.DataFrame(a, columns=[\"PCA Comp\", \"Explained Variance\"])\n",
    "\n",
    "# Trying to hit 95%\n",
    "print(\"Variance explain with 2 n_compononets: \", sum(a[\"Explained Variance\"][0:2]))\n",
    "print(\"Variance explain with 3 n_compononets: \", sum(a[\"Explained Variance\"][0:3]))\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the Data\n",
    "plt.figure(1, figsize=(14, 8))\n",
    "plt.plot(pca.explained_variance_ratio_, linewidth=2, c=\"r\")\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('explained_ratio_')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6189da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = X_train\n",
    "y_num = predictions\n",
    "\n",
    "target_names = [\"Cluster 0\",\"Cluster 1\",\"Cluster 2\",\"Cluster 3\"]\n",
    "\n",
    "pca = PCA(n_components=2, random_state = 42)\n",
    "X_r = pca.fit(X).transform(X)\n",
    "\n",
    "\n",
    "# Percentage of variance explained for each components\n",
    "print('Explained variance ratio (first two components): %s' % str(pca.explained_variance_ratio_))\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure()\n",
    "plt.figure(figsize=(12,8))\n",
    "colors = ['navy', 'turquoise', 'darkorange', 'red']\n",
    "lw = 2\n",
    "\n",
    "\n",
    "for color, i, target_name in zip(colors, [0, 1, 2,3], target_names):\n",
    "    plt.scatter(X_r[y_num == i, 0], X_r[y_num == i, 1], color=color, alpha=.8, lw=lw,label=target_name)\n",
    "    \n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.6)   \n",
    "plt.title('PCA of 2 Items')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d441297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the cluster column to raw_data to determine each client to which cluster\n",
    "raw_data['cluster']=pd.Series(predictions, index=raw_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5940a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing categorical\n",
    "categorical = raw_data.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb022d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate all the categorical percentage\n",
    "\n",
    "def cal_percentage(df,x):\n",
    "    y =df[x].value_counts(normalize=True)*100\n",
    "    print(f'The percentage of {x} is: \\n {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ce0559",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_rate_cluster0 = raw_data.loc[raw_data['cluster']== 0]\n",
    "churn_rate_cluster1 = raw_data.loc[raw_data['cluster']== 1]\n",
    "churn_rate_cluster2 = raw_data.loc[raw_data['cluster']== 2]\n",
    "churn_rate_cluster3 = raw_data.loc[raw_data['cluster']== 3]\n",
    "clusters_frames= [churn_rate_cluster2]\n",
    "\n",
    "for df in clusters_frames:\n",
    "    churn_rate = len(df.loc[df['Attrition_Flag']== 'Attrited Customer'])*100/len(raw_data)\n",
    "    print(f'The churn rate of the is:  {churn_rate}')\n",
    "    for f in categorical.columns:\n",
    "        cal_percentage(df,f)\n",
    "print('####################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6964ba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The charachtersitics for first cluster are : \n",
      " Charachteristics    Information\n",
      "------------------  ----------------------------------\n",
      "Churn-rate          10.53%\n",
      "Gender              53% Female\n",
      "Education level     31% Graduated then 20% High school\n",
      "Marital Status      46% Marrid and 39% singels\n",
      "Incom Category      33% less than 40k and 20% 40k-60k\n",
      "Card Category       97% Blue\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "# creating charachter's table for each cluster:\n",
    "cluster0_data = [[\"Churn-rate\",'10.53%'],\n",
    "                 [\"Gender\",\"53% Female\" ],\n",
    "                 [\"Education level\",\"31% Graduated then 20% High school\"],\n",
    "                 [\"Marital Status\",\"46% Marrid and 39% singels\"],\n",
    "                 [\"Income Category\", \"33% less than 40k and 20% 40k-60k\"],\n",
    "                 [\"Card Category\", \"97% Blue\"]]\n",
    "\n",
    "col_names = [\"Charachteristics\", \"Information\"]\n",
    "#display table\n",
    "print('The charachtersitics for first cluster are : \\n',tabulate(cluster0_data, headers=col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e17cf633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The charachtersitics for second cluster are : \n",
      " Charachteristics    Information\n",
      "------------------  -----------------------------------------------------------\n",
      "Churn-rate          0.32%\n",
      "Gender              60% Male\n",
      "Education level     31% Graduated and 21% High school\n",
      "Marital Status      45% Marrid and 39% singels\n",
      "Incom Category      29% less than 40k and 18% for 40k-60k, 60k-80k and 80k-120k\n",
      "Card Category       79% Blue and 16% Silver\n"
     ]
    }
   ],
   "source": [
    "# creating charachter's table for each cluster:\n",
    "cluster1_data = [[\"Churn-rate\",'0.32%'],\n",
    "                 [\"Gender\",\"60% Male\" ],\n",
    "                 [\"Education level\",\"31% Graduated and 21% High school\"],\n",
    "                 [\"Marital Status\",\"45% Marrid and 39% singels\"],\n",
    "                 [\"Incom Category\", \"29% less than 40k and 18% for 40k-60k, 60k-80k and 80k-120k\"],\n",
    "                 [\"Card Category\", \"79% Blue and 16% Silver\"]]\n",
    "\n",
    "col_names = [\"Charachteristics\", \"Information\"]\n",
    "#display table\n",
    "print('The charachtersitics for second cluster are : \\n',tabulate(cluster1_data, headers=col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae3c0efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The charachtersitics for third cluster are : \n",
      " Charachteristics    Information\n",
      "------------------  --------------------------------------------------\n",
      "Churn-rate          2.95%\n",
      "Gender              72% Female\n",
      "Education level     31% Graduated , 20% High school and 14% uneducated\n",
      "Marital Status      49% Marrid  and 40% Singel\n",
      "Incom Category      54% less than 40k and 21% 40k-60k\n",
      "Card Category       100% Blue\n"
     ]
    }
   ],
   "source": [
    "# creating charachter's table for each cluster:\n",
    "cluster1_data = [[\"Churn-rate\",'2.95%'],\n",
    "                 [\"Gender\",\"72% Female\" ],\n",
    "                 [\"Education level\",\"31% Graduated , 20% High school and 14% uneducated\"],\n",
    "                 [\"Marital Status\",\"49% Marrid  and 40% Singel\"],\n",
    "                 [\"Incom Category\", \"54% less than 40k and 21% 40k-60k\"],\n",
    "                 [\"Card Category\", \"100% Blue\"]]\n",
    "\n",
    "col_names = [\"Charachteristics\", \"Information\"]\n",
    "#display table\n",
    "print('The charachtersitics for third cluster are : \\n',tabulate(cluster1_data, headers=col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6dd3f511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The charachtersitics for fourth cluster are : \n",
      " Charachteristics    Information\n",
      "------------------  --------------------------------------------------\n",
      "Churn-rate          2.25%\n",
      "Gender              87% Male\n",
      "Education level     30% Graduated , 19% High school and 16% uneducated\n",
      "Marital Status      43% singels and 40% Marrid\n",
      "Incom Category      40% 80k-120k and 26% 120k\n",
      "Card Category       71% Blue and 23% Silver\n"
     ]
    }
   ],
   "source": [
    "# creating charachter's table for each cluster:\n",
    "cluster1_data = [[\"Churn-rate\",'2.25%'],\n",
    "                 [\"Gender\",\"87% Male\" ],\n",
    "                 [\"Education level\",\"30% Graduated , 19% High school and 16% uneducated\"],\n",
    "                 [\"Marital Status\",\"43% singels and 40% Marrid\"],\n",
    "                 [\"Incom Category\", \"40% 80k-120k and 26% 120k\"],\n",
    "                 [\"Card Category\", \"71% Blue and 23% Silver\"]]\n",
    "\n",
    "col_names = [\"Charachteristics\", \"Information\"]\n",
    "#display table\n",
    "print('The charachtersitics for fourth cluster are : \\n',tabulate(cluster1_data, headers=col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63919431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\user\\\\Desktop\\\\AI projects\\\\Churn-prediction\\\\ChurnProject\\\\churn_main\\\\KmeansModel.joblib']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the model into a pickel file\n",
    "\n",
    "from joblib import dump\n",
    "dump(km, 'C:\\\\Users\\\\user\\\\Desktop\\\\AI projects\\\\Churn-prediction\\\\ChurnProject\\\\churn_main\\\\KmeansModel.joblib') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
